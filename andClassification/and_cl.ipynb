{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd0efda-db19-4ac4-8948-e56735c5691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data: 1000 AND logic\n",
    "    input: 1 value = sum of 2 input value (from 0 to 1)\n",
    "    output: 1 prediction of logic\n",
    "\n",
    "no framework\n",
    "model: 1 logistic regression neuron\n",
    "    layers: 1 neuron\n",
    "    params: learning rate 0.0005\n",
    "    hyperparams: X\n",
    "    algorithm: BinaryCrossEntropy loss\n",
    "\n",
    "result: my dataset is fire!\n",
    "    test:\n",
    "    1000 iteration: (me struggling don't know why loss is linear)\n",
    "    100000 iteration: sigmoid start to form\n",
    "    500000 iteration: sigmoid start to fit\n",
    "    1000000 iteration: finally, it worked\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8c38f-bab1-4583-ab13-83fb77dc058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.loadtxt(\"and.csv\", delimiter=\",\", skiprows=1)\n",
    "feature = data[:,0] + data[:,1]\n",
    "label = data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12a1a3-54a9-4802-8052-fb8a84f09251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    global w, b\n",
    "    w = np.random.rand(1, 1) * np.sqrt(2/1)\n",
    "    b = np.zeros((1, 1))\n",
    "    return w, b\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58788b1c-248a-4dfa-94e1-2cbc510d6cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(feature, w, b):\n",
    "    return sigmoid(feature * w + b)\n",
    "\n",
    "def backward(feature, label, prediction):\n",
    "    dj = label - prediction\n",
    "    dw = -1 / 1000 * (dj @ feature.T)\n",
    "    db = -np.sum(dj, axis = 1, keepdims = True)\n",
    "    return dw, db\n",
    "\n",
    "def update_params(w, b, dw, db):\n",
    "    w = w - 0.001 * dw\n",
    "    b = b - 0.001 * db\n",
    "    return w, b\n",
    "\n",
    "def BCE(label, prediction):\n",
    "    return -np.sum(label * (np.log(prediction)) + (1 - label) * (np.log(1 - prediction)))\n",
    "\n",
    "def train():\n",
    "    history = []\n",
    "    w, b = init_params()\n",
    "    for iteration in range (500000):\n",
    "        prediction = forward(feature, w, b)\n",
    "        dw, db = backward(feature, label, prediction)\n",
    "        w, b = update_params(w, b, dw, db)\n",
    "        loss = BCE(label, prediction)\n",
    "        history.append(loss)\n",
    "        if (iteration % 50000 == 0):\n",
    "            print(f\"iteration {iteration}: loss = {loss:.4f}\")\n",
    "    return history, w, b\n",
    "history, w, b = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d32c011-d2c7-4ce5-a87e-70e8fda3fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_w = w.item()\n",
    "scalar_b = b.item()\n",
    "\n",
    "plt.scatter(feature, label, color='blue', alpha=0.5)\n",
    "x_vals = np.linspace(np.min(feature), np.max(feature), 100)\n",
    "y_vals = sigmoid(scalar_w * x_vals + scalar_b)\n",
    "plt.plot(x_vals, y_vals, color='red')\n",
    "\n",
    "plt.xlabel(\"Feature (x)\")\n",
    "plt.ylabel(\"Label (y)\")\n",
    "plt.title(\"This good\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
